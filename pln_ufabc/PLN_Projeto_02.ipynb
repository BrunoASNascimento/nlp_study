{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PLN - Projeto 02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN3nzv+Y01XWPm/GMhzVhmu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoASNascimento/nlp_study/blob/develop/pln_ufabc/PLN_Projeto_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_niAnjcJHeY"
      },
      "source": [
        "**Nome:** Bruno Araújo Santos do Nascimento\n",
        "\n",
        "**RA:** 11201720606"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbGrnHcuKIdt"
      },
      "source": [
        "# Técnicas utilizadas:\n",
        "\n",
        "Similaridade de Textos e Reconhecimento de Entidades Nomeadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JionnarWQRnq"
      },
      "source": [
        "## Instalações:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MvBRfW6QYk5",
        "outputId": "db738c04-c496-4266-ccb4-e93a713cf848"
      },
      "source": [
        "!python -m spacy download pt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2 MB 502 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Building wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-py3-none-any.whl size=21186282 sha256=3788969b5fa7ae4dc8bb6348eb22be146ace566154f7aee8d0ff1da8abdcdc4d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g76se5k4/wheels/c3/f9/0c/5c014a36941a00f5df5fc0756cb961d7c457a978e697a6ce3b\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXhn4pF5Qb3b"
      },
      "source": [
        "## Imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt7pf_Q0QbCL"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import spacy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHRcrec-RWJr"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck9uNarGS12Q"
      },
      "source": [
        "## Nltk downloads:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfqqxdSzS1Ej"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ7HWUyXQ4Ok"
      },
      "source": [
        "## Textos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIKcKWuzQ7Pl"
      },
      "source": [
        "text_01 = ''' \n",
        "Essa ferramenta pode ser utilizada para comparar as modificações entre dois textos. \n",
        "O primeiro texto refere-se a um documento criado anteriormente e que foi editado no segundo texto.\n",
        "Trecho que foi removido.\n",
        "'''\n",
        "text_02 = ''' \n",
        "Essa ferramenta pode ser utilizada para comparar as modificações entre dois textos, ou seja, texto1 X texto2. \n",
        "O primeiro texto refere-se a um documento criado anteriormente e que foi modificado no segundo texto.\n",
        "Novo parágrafo adicionado.\n",
        "'''\n",
        "text_03 = ''' \n",
        "O Brasil registrou neste domingo (5) 68 mortes por Covid-19 nas últimas 24 horas, com o total de óbitos chegando a 615.674 desde o início da pandemia. \n",
        "Com isso, a média móvel de mortes nos últimos 7 dias ficou em 194, a menor desde o dia 22 de abril de 2020. \n",
        "Em comparação à média de 14 dias atrás, a variação foi de -7% e aponta tendência de estabilidade pelo nono dia seguido.\n",
        "'''"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQSspoLMKh7Z"
      },
      "source": [
        "## Similaridade de Textos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTiymCN1I38u",
        "outputId": "f8286d94-7d9a-4c28-8896-b329b80d1d35"
      },
      "source": [
        "stemmer = nltk.stem.porter.PorterStemmer()\n",
        "stop_words = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "\n",
        "string_without_punctuation = dict((ord(char), None) for char in string.punctuation)\n",
        "\n",
        "def stem_tokens(tokens):\n",
        "    return [stemmer.stem(item) for item in tokens]\n",
        "\n",
        "def normalize(text):\n",
        "    return stem_tokens(nltk.word_tokenize(text.lower().translate(string_without_punctuation)))\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words=stopwords)\n",
        "\n",
        "def cosine_sim(text1, text2):\n",
        "    tfidf = vectorizer.fit_transform([text1, text2])\n",
        "    return ((tfidf * tfidf.T).A)[0,1]\n",
        "\n",
        "\n",
        "print(f\"A semelhança entre os textos 1 e 2 é de {cosine_sim(text_01, text_02)*100:.1f}%.\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A semelhança entre os textos 1 e 2 é de 70.5%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBoGb0-lTIii",
        "outputId": "3d29ba98-5023-4c83-dfa7-3138f493d35b"
      },
      "source": [
        "print(f\"A semelhança entre os textos 1 e 3 é de {cosine_sim(text_01, text_03)*100:.1f}%.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A semelhança entre os textos 1 e 3 é de 0.0%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzYQ8Lf5QLR5"
      },
      "source": [
        "## Reconhecimento de Entidades Nomeadas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9KRRjKlLCcv",
        "outputId": "dde4a0dd-ace5-49d8-8171-a95d19516ab0"
      },
      "source": [
        "nlp = spacy.load('pt')\n",
        "\n",
        "doc = nlp(text_03)\n",
        "for entity in doc.ents:\n",
        "    print(f\"Entidade: {entity} -> {entity.label_}.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entidade: Brasil -> LOC\n"
          ]
        }
      ]
    }
  ]
}